{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 1 Milestone Report\n",
    "\n",
    "#### By: Huong Ivy Nguyen, Ph.D. \n",
    "\n",
    "### Stated Problem: \n",
    "This capstone project is inspired by a Kaggle competition posted and hosted by Intel and MobileODT. The main goal of this project is to develop a new algorithm that can effectively identify the type of cervix a patient has based on images. This workflow will help health providers give proper cervical cancer treatment referral to their patients. \n",
    "Cervical cancer is classified as a easy-to-prevent cancer if caught in its precancerous stage. According to the American Cancer Society, cervical cancer is one of the most successfully treatable cancers if detected early.  However, one of the most problematic issue in treating patients with this type of cancer is the ability to identify an appropriate treatment that works effectively and accordingly to the patientâ€™s physiological needs. In rural parts of the world, many women who are susceptible to cervical cancer are receiving treatment that will not work due to the position of their cervix. In order to solve this problem, it would be necessary to develop an algorithm that could help health providers identify the type of cervix that a patient has based on images. \n",
    "\n",
    "### Data Wrangling Process:\n",
    "The data wrangling process was conducted based on the following outline: \n",
    "+ Step 1: Generate a pandas dataframe that includes the image directory paths and the type of cervix image for the training dataset\n",
    "+ Step 2: Visualize some sample images of each cervix type of the training dataset to get a sense how different the types are\n",
    "+ Step 3: Create a new dataframe that include the following columns for the training dataset:\n",
    "    + Image directory\n",
    "    + Cervix type \n",
    "    + Image height\n",
    "    + Image width\n",
    "    + Image channels\n",
    "+ Step 4: Write the dataframe generated in step 3 to a csv file (training_images_size.csv)\n",
    "+ Step 5: Create a dataframe that includes the following columns for the testing dataset:\n",
    "    + Image directory\n",
    "    + Image height\n",
    "    + Image width\n",
    "    + Image channels\n",
    "+ Step 6: Convert the generated dataframe in step 5 to a csv file for later use (testing_images_size.csv)\n",
    "\n",
    "### Explainatory Data Analysis and Inferential Statistics:\n",
    "+ All the images were mainly taken by either Motorola or Samsung cameras. Even though the images were not taken by the same make/model, the inferential statistical analysis showed that there is no difference in term of image resolution across all images of both the training and the testing dataset.\n",
    "\n",
    "![](capstone1_milestone/make_datetime_trainset.png)\n",
    "\n",
    "![](capstone1_milestone/make_datetime_testset.png)\n",
    "\n",
    "![](capstone1_milestone/mean_diff_size.png)\n",
    "\n",
    "\n",
    "+ According to the bar charts generated for each cervix type of the training dataset, June 2016 seems to be the timeframe that a majority of images were taken.\n",
    "\n",
    "+ When comparing among the average images of the three cervix types of the training dataset, it appears that Type 1 has the brightest features (least color contrast).\n",
    "\n",
    "![](capstone1_milestone/average_img.png)\n",
    "\n",
    "\n",
    "+ Finally, by constructing a ssim heatmap, we could potentially identify a region of images that have less structureal similarity to the other images.\n",
    "\n",
    "![](capstone1_milestone/heatmap_type1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
