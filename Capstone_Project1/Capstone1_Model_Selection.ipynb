{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob \n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "train = pd.read_csv('training_images_size.csv', sep='\\t')\n",
    "test = pd.read_csv('testing_images_size.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 100\n",
    "img_w = 100\n",
    "def read_img(path,):\n",
    "    'read, resize, and convert an image to grayscale'\n",
    "    img = cv2.imread(path)\n",
    "    resize = cv2.resize(img, (img_h, img_w), cv2.INTER_LINEAR)\n",
    "    #gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = train.imagepath.values\n",
    "test_paths = glob('test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(train_path):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    train_id = []\n",
    "    start_time = time.time()\n",
    "    for path in train_paths:\n",
    "        train_id.append(path)\n",
    "        train_data.append(read_img(path))\n",
    "        target = path.split('/')[1]\n",
    "        target = target.split('_')[1]\n",
    "        train_target.append(target)\n",
    "    print ('Training data load time: {}'.format(time.time() - start_time))\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "def load_test(test_paths):\n",
    "    test_data = []\n",
    "    test_id = []\n",
    "    start_time = time.time()\n",
    "    for path in test_paths:\n",
    "        test_id.append(path)\n",
    "        test_data.append(read_img(path))\n",
    "    print ('Testing data load time: {}'.format(time.time() - start_time))\n",
    "    return test_data, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data load time: 261.52671217918396\n",
      "Testing data load time: 91.19738173484802\n"
     ]
    }
   ],
   "source": [
    "train_data, train_target, train_id = load_train(train_paths)\n",
    "test_data, test_id = load_test(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (1481, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data):\n",
    "    data = np.array(data, dtype=np.uint8)\n",
    "    data = data.astype('float32')\n",
    "    data = data/255\n",
    "    return data\n",
    "\n",
    "train_data = normalize_data(train_data)\n",
    "print ('Shape of the training data is ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (503, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "test_data = normalize_data(test_data)\n",
    "print ('Shape of the training data is ', test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_target to one-hot-encoding before fitting into the model\n",
    "train_label = np_utils.to_categorical(train_target)\n",
    "train_label = np.transpose(train_label)\n",
    "train_label = np.transpose(train_label[~(train_label==0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation split \n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_label, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping callback\n",
    "patience = 5\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0.02, \n",
    "                              patience = patience, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 55s 46ms/step - loss: 1.0272 - acc: 0.5203 - val_loss: 1.0214 - val_acc: 0.5118\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 52s 44ms/step - loss: 1.0041 - acc: 0.5312 - val_loss: 1.0330 - val_acc: 0.5118\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 53s 45ms/step - loss: 0.9976 - acc: 0.5312 - val_loss: 1.0154 - val_acc: 0.5118\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 59s 50ms/step - loss: 0.9993 - acc: 0.5312 - val_loss: 1.0181 - val_acc: 0.5118\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 56s 47ms/step - loss: 0.9990 - acc: 0.5312 - val_loss: 1.0174 - val_acc: 0.5118\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 56s 48ms/step - loss: 0.9988 - acc: 0.5312 - val_loss: 1.0182 - val_acc: 0.5118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aed6f020588>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the first model with a simple stack of 3 convolution layers with a ReLU activation and max_pooling\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, 3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, (3,3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "#Add flatten\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model1.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping], \n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 3,371,075\n",
      "Trainable params: 3,371,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Deep Convolutional NetWorks for Large-Scale Image Recognition (VGG16 Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "weights_path = get_file('vgg16_weights.h5', WEIGHTS_PATH_NO_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense\n",
    "vgg16_model = VGG16(weights = 'imagenet', include_top=False, \n",
    "                   input_shape=(img_w, img_h, 3))\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape = vgg16_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3,activation='sigmoid'))\n",
    "\n",
    "model2 = Model(input=vgg16_model.input, output=top_model(vgg16_model.output))\n",
    "model2.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_24 (Sequential)   (None, 3)                 1180675   \n",
      "=================================================================\n",
      "Total params: 15,895,363\n",
      "Trainable params: 15,895,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 1042s 880ms/step - loss: 1.1008 - acc: 0.2162 - val_loss: 1.0986 - val_acc: 0.1818\n",
      "Epoch 2/50\n",
      " 128/1184 [==>...........................] - ETA: 15:21 - loss: 1.0986 - acc: 0.1797"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping], \n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
