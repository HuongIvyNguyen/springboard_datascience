{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob \n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 224\n",
    "img_w = 224\n",
    "def read_img(path,):\n",
    "    'read, resize, and convert an image to grayscale'\n",
    "    img = cv2.imread(path)\n",
    "    resize = cv2.resize(img, (img_h, img_w), cv2.INTER_LINEAR)\n",
    "    #gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_paths = glob('/storage/Documents/springboard_capstone/capstone1/train/*')\n",
    "test_paths = glob('/storage/Documents/springboard_capstone/capstone1/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = []\n",
    "for path in type_paths:\n",
    "    train_paths += glob(path+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(paths):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    train_id = []\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        train_id.append(path)\n",
    "        train_data.append(read_img(path))\n",
    "        target = path.split('/')[-2]\n",
    "        train_target.append(target)\n",
    "    print ('Training data load time: {}'.format(time.time() - start_time))\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "def load_test(paths):\n",
    "    test_data = []\n",
    "    test_id = []\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        test_id.append(path)\n",
    "        test_data.append(read_img(path))\n",
    "    print ('Testing data load time: {}'.format(time.time() - start_time))\n",
    "    return test_data, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data load time: 342.038950920105\n",
      "Testing data load time: 123.54733157157898\n"
     ]
    }
   ],
   "source": [
    "train_data, train_target, train_id_ = load_train(train_paths)\n",
    "test_data, test_id_ = load_test(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (1481, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data):\n",
    "    data = np.array(data, dtype=np.uint8)\n",
    "    data = data.astype('float32')\n",
    "    data = data/255\n",
    "    return data\n",
    "\n",
    "train_data = normalize_data(train_data)\n",
    "print ('Shape of the training data is ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (503, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_data = normalize_data(test_data)\n",
    "print ('Shape of the training data is ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_target to one-hot-encoding before fitting into the model\n",
    "train_label = [int(x.split('_')[1]) for x in train_target]\n",
    "train_label = np_utils.to_categorical(train_label)\n",
    "train_label = np.transpose(train_label)\n",
    "train_label = np.transpose(train_label[~(train_label==0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation split \n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_label, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping callback\n",
    "patience = 4\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0.05, \n",
    "                              patience = patience, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build the first model with a simple stack of 3 convolution layers with a ReLU activation and max_pooling\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, 3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, (3,3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "#Add flatten\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               22151424  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 22,245,443\n",
      "Trainable params: 22,245,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 376s 318ms/step - loss: 1.0104 - acc: 0.5312 - val_loss: 1.0173 - val_acc: 0.5118\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 357s 302ms/step - loss: 1.0059 - acc: 0.5270 - val_loss: 1.0164 - val_acc: 0.5118\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 325s 274ms/step - loss: 0.9942 - acc: 0.5312 - val_loss: 1.0145 - val_acc: 0.5118\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 299s 252ms/step - loss: 0.9832 - acc: 0.5321 - val_loss: 1.0087 - val_acc: 0.5118\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 282s 238ms/step - loss: 0.9607 - acc: 0.5312 - val_loss: 0.9629 - val_acc: 0.5118\n",
      "The time for fitting training data into model 1 is 1639.1563205718994\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model1.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping],\n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The time for fitting training data into model 1 is {}'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Deep Convolutional NetWorks for Large-Scale Image Recognition (VGG16 Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model \n",
    "\n",
    "vgg16_model = VGG16(weights = 'imagenet', include_top=False, \n",
    "                   input_shape=(img_w, img_h, 3))\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape = vgg16_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model2 = Model(input=vgg16_model.input, output=top_model(vgg16_model.output))\n",
    "model2.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 3)                 6423555   \n",
      "=================================================================\n",
      "Total params: 21,138,243\n",
      "Trainable params: 21,138,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 4532s 4s/step - loss: 12.7385 - acc: 0.1934 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 4646s 4s/step - loss: 13.3410 - acc: 0.1723 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 4649s 4s/step - loss: 13.4499 - acc: 0.1655 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 5276s 4s/step - loss: 13.4635 - acc: 0.1647 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 5414s 5s/step - loss: 13.3818 - acc: 0.1698 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "The time for fitting training data into model 2 is 24517.816619873047\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model2.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping], \n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The time for fitting training data into model 2 is {}'.format(end_time-start_time))\n",
    "model2.save_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/ives/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model \n",
    "\n",
    "resnet50_model = ResNet50(weights = 'imagenet', include_top=False, \n",
    "                   input_shape=(img_w, img_h, 3))\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape =resnet50_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.5))\n",
    "add_model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model3 = Model(input=resnet50_model.input, output=add_model(resnet50_model.output))\n",
    "model3.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 3016s 3s/step - loss: 7.5120 - acc: 0.5270 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 2855s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 2537s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 2509s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 2553s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "The time for fitting training data into model 3 is 13474.341937065125\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model3.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping], \n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The time for fitting training data into model 3 is {}'.format(end_time-start_time))\n",
    "\n",
    "model3.save_weights('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TUNING ON MODEL 1 USING DIFFERENT COMBINATION OF LOSS FUNCTION AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(loss_function, optimizer):\n",
    "    model = Sequential()\n",
    "    kernel_size=(3,3)\n",
    "    data_size=(224,224,3)\n",
    "    for i in range(5, 8):\n",
    "        model.add(Conv2D(2^i, kernel_size, input_shape=data_size, data_format='channels_last'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss=loss_function, optimizer = optimizer, \n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "loss_functions = ['mean_squared_error', \n",
    "                 'categorical_crossentropy', \n",
    "                 'binary_crossentropy']\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adadelta = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "optimizers = [sgd, adadelta, adam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of combinations is  9\n"
     ]
    }
   ],
   "source": [
    "combinations = [loss_functions, optimizers]\n",
    "import itertools\n",
    "combinations = list(itertools.product(*combinations))\n",
    "print ('The number of combinations is ', len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mew Early stopping callback\n",
    "patience = 10\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0.01, \n",
    "                              patience = patience, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function:  mean_squared_error\n",
      "Optimizer:  <keras.optimizers.SGD object at 0x2b4edb69c278>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 34s 29ms/step - loss: 0.2042 - acc: 0.5152 - val_loss: 0.2118 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-0.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 34s 29ms/step - loss: 0.2010 - acc: 0.5304 - val_loss: 0.2088 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.1992 - acc: 0.5321 - val_loss: 0.2068 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.1968 - acc: 0.5312 - val_loss: 0.2040 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51178\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 49s 41ms/step - loss: 0.1941 - acc: 0.5355 - val_loss: 0.2013 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.51178 to 0.52525, saving model to Model1-0.h5\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1949 - acc: 0.5279 - val_loss: 0.2008 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.52525\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1902 - acc: 0.5355 - val_loss: 0.2038 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.52525\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1896 - acc: 0.5456 - val_loss: 0.2012 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.52525\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1875 - acc: 0.5600 - val_loss: 0.1990 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.52525 to 0.52525, saving model to Model1-0.h5\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 48s 41ms/step - loss: 0.1846 - acc: 0.5693 - val_loss: 0.1968 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.52525\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1826 - acc: 0.5693 - val_loss: 0.1995 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.52525\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1792 - acc: 0.5701 - val_loss: 0.1952 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.52525 to 0.53199, saving model to Model1-0.h5\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.1774 - acc: 0.5912 - val_loss: 0.1956 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53199\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 47s 39ms/step - loss: 0.1760 - acc: 0.5938 - val_loss: 0.1958 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.53199 to 0.53535, saving model to Model1-0.h5\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1722 - acc: 0.5954 - val_loss: 0.1947 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.53535\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 43s 37ms/step - loss: 0.1721 - acc: 0.6081 - val_loss: 0.1953 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.53535\n",
      "Epoch 17/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1708 - acc: 0.6284 - val_loss: 0.1937 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.53535\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 49s 42ms/step - loss: 0.1635 - acc: 0.6267 - val_loss: 0.1943 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.53535\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.1659 - acc: 0.6275 - val_loss: 0.1957 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.53535\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1617 - acc: 0.6326 - val_loss: 0.1968 - val_acc: 0.4983\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.53535\n",
      "Epoch 21/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.1591 - acc: 0.6588 - val_loss: 0.1970 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.53535\n",
      "Epoch 22/50\n",
      "1184/1184 [==============================] - 49s 41ms/step - loss: 0.1611 - acc: 0.6427 - val_loss: 0.1983 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.53535\n",
      "Epoch 23/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1567 - acc: 0.6520 - val_loss: 0.1995 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.53535\n",
      "Epoch 24/50\n",
      "1184/1184 [==============================] - 43s 37ms/step - loss: 0.1509 - acc: 0.6833 - val_loss: 0.1978 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.53535\n",
      "Training time for this model is 1070.9721937179565\n",
      "\n",
      "\n",
      "Loss function:  mean_squared_error\n",
      "Optimizer:  <keras.optimizers.Adagrad object at 0x2b4edb69c240>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.2851 - acc: 0.5245 - val_loss: 0.2174 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-1.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.2066 - acc: 0.5203 - val_loss: 0.2108 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.2013 - acc: 0.5296 - val_loss: 0.2081 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1966 - acc: 0.5312 - val_loss: 0.2080 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51178\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.1954 - acc: 0.5329 - val_loss: 0.2044 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.51178\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.1923 - acc: 0.5532 - val_loss: 0.2027 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.51178 to 0.53199, saving model to Model1-1.h5\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 50s 42ms/step - loss: 0.1882 - acc: 0.5515 - val_loss: 0.1979 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53199\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.1883 - acc: 0.5600 - val_loss: 0.2031 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53199\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 47s 39ms/step - loss: 0.1819 - acc: 0.5853 - val_loss: 0.1982 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.53199 to 0.53535, saving model to Model1-1.h5\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1841 - acc: 0.5650 - val_loss: 0.1983 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53535\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 49s 41ms/step - loss: 0.1801 - acc: 0.5777 - val_loss: 0.2011 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53535\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.1745 - acc: 0.5997 - val_loss: 0.1994 - val_acc: 0.5421\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.53535 to 0.54209, saving model to Model1-1.h5\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 40s 33ms/step - loss: 0.1722 - acc: 0.5963 - val_loss: 0.1989 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.54209\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1646 - acc: 0.6292 - val_loss: 0.1987 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.54209\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1649 - acc: 0.6284 - val_loss: 0.1984 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.54209\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1629 - acc: 0.6334 - val_loss: 0.2022 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.54209\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1623 - acc: 0.6267 - val_loss: 0.2017 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.54209\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1542 - acc: 0.6529 - val_loss: 0.2054 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.54209\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1494 - acc: 0.6639 - val_loss: 0.2054 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.54209\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1449 - acc: 0.6900 - val_loss: 0.2092 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.54209\n",
      "Epoch 21/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.1424 - acc: 0.6765 - val_loss: 0.2065 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.54209\n",
      "Epoch 22/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1381 - acc: 0.7035 - val_loss: 0.2079 - val_acc: 0.4949\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.54209\n",
      "Training time for this model is 941.0249173641205\n",
      "\n",
      "\n",
      "Loss function:  mean_squared_error\n",
      "Optimizer:  <keras.optimizers.Adam object at 0x2b4edb69c320>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.2058 - acc: 0.5177 - val_loss: 0.2176 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52525, saving model to Model1-2.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.2005 - acc: 0.5329 - val_loss: 0.2165 - val_acc: 0.4848\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.52525\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 36s 31ms/step - loss: 0.1998 - acc: 0.5389 - val_loss: 0.2121 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.52525\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1978 - acc: 0.5279 - val_loss: 0.2123 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.52525 to 0.52862, saving model to Model1-2.h5\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1953 - acc: 0.5346 - val_loss: 0.2102 - val_acc: 0.4983\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.52862\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1946 - acc: 0.5481 - val_loss: 0.2086 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.52862 to 0.53199, saving model to Model1-2.h5\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1908 - acc: 0.5574 - val_loss: 0.2070 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53199\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.1889 - acc: 0.5549 - val_loss: 0.2056 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53199\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1772 - acc: 0.5870 - val_loss: 0.2012 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53199\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 37s 32ms/step - loss: 0.1710 - acc: 0.6090 - val_loss: 0.2015 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53199\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1687 - acc: 0.6174 - val_loss: 0.2031 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53199\n",
      "Training time for this model is 419.04780745506287\n",
      "\n",
      "\n",
      "Loss function:  categorical_crossentropy\n",
      "Optimizer:  <keras.optimizers.SGD object at 0x2b4edb69c278>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 1.0390 - acc: 0.5177 - val_loss: 1.0265 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-3.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 1.0033 - acc: 0.5312 - val_loss: 1.0207 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.9980 - acc: 0.5312 - val_loss: 1.0176 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 0.9978 - acc: 0.5312 - val_loss: 1.0152 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51178\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.9988 - acc: 0.5312 - val_loss: 1.0155 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.51178\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 41s 34ms/step - loss: 0.9994 - acc: 0.5312 - val_loss: 1.0167 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.51178\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.9960 - acc: 0.5312 - val_loss: 1.0159 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.51178\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9966 - acc: 0.5312 - val_loss: 1.0171 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.51178\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.9975 - acc: 0.5312 - val_loss: 1.0174 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.51178\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.9969 - acc: 0.5312 - val_loss: 1.0163 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.51178\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.9982 - acc: 0.5312 - val_loss: 1.0165 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.51178\n",
      "Training time for this model is 450.9990496635437\n",
      "\n",
      "\n",
      "Loss function:  categorical_crossentropy\n",
      "Optimizer:  <keras.optimizers.Adagrad object at 0x2b4edb69c240>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 1.2522 - acc: 0.4958 - val_loss: 1.0347 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52189, saving model to Model1-4.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.9994 - acc: 0.5279 - val_loss: 1.0262 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.52189 to 0.52525, saving model to Model1-4.h5\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 41s 34ms/step - loss: 0.9790 - acc: 0.5372 - val_loss: 1.0267 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.52525\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.9678 - acc: 0.5389 - val_loss: 1.0228 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.52525 to 0.53199, saving model to Model1-4.h5\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9768 - acc: 0.5380 - val_loss: 1.0238 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.53199\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9635 - acc: 0.5346 - val_loss: 1.0248 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.53199\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 41s 34ms/step - loss: 0.9535 - acc: 0.5431 - val_loss: 1.0251 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53199\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 40s 33ms/step - loss: 0.9462 - acc: 0.5574 - val_loss: 1.0244 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53199\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9455 - acc: 0.5422 - val_loss: 1.0242 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53199\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9425 - acc: 0.5422 - val_loss: 1.0256 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53199\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9424 - acc: 0.5422 - val_loss: 1.0246 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53199\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9175 - acc: 0.5524 - val_loss: 1.0225 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.53199\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9046 - acc: 0.5701 - val_loss: 1.0165 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53199\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.8865 - acc: 0.5726 - val_loss: 1.0164 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.53199\n",
      "Training time for this model is 556.4695749282837\n",
      "\n",
      "\n",
      "Loss function:  categorical_crossentropy\n",
      "Optimizer:  <keras.optimizers.Adam object at 0x2b4edb69c320>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 1.0512 - acc: 0.5084 - val_loss: 1.0173 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-5.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 1.0009 - acc: 0.5312 - val_loss: 1.0153 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 36s 30ms/step - loss: 0.9982 - acc: 0.5312 - val_loss: 1.0158 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.9986 - acc: 0.5312 - val_loss: 1.0156 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51178\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.9967 - acc: 0.5312 - val_loss: 1.0146 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.51178\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9951 - acc: 0.5279 - val_loss: 1.0147 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.51178\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9909 - acc: 0.5279 - val_loss: 1.0153 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.51178\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.9810 - acc: 0.5338 - val_loss: 1.0140 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.51178\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.9720 - acc: 0.5304 - val_loss: 1.0237 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.51178\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9578 - acc: 0.5321 - val_loss: 1.0178 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.51178 to 0.52189, saving model to Model1-5.h5\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9510 - acc: 0.5414 - val_loss: 1.0242 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.52189\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9369 - acc: 0.5422 - val_loss: 1.0185 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.52189\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9258 - acc: 0.5532 - val_loss: 1.0350 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.52189\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.9069 - acc: 0.5515 - val_loss: 1.0460 - val_acc: 0.4882\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.52189\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 37s 32ms/step - loss: 0.9003 - acc: 0.5785 - val_loss: 1.0224 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.52189\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.8721 - acc: 0.5921 - val_loss: 1.0391 - val_acc: 0.4983\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.52189\n",
      "Epoch 17/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.8550 - acc: 0.5929 - val_loss: 1.0462 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.52189\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.8390 - acc: 0.6073 - val_loss: 1.0500 - val_acc: 0.4949\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.52189\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.7988 - acc: 0.6166 - val_loss: 1.0620 - val_acc: 0.4916\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.52189\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 37s 32ms/step - loss: 0.7783 - acc: 0.6275 - val_loss: 1.0905 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.52189\n",
      "Training time for this model is 756.5391731262207\n",
      "\n",
      "\n",
      "Loss function:  binary_crossentropy\n",
      "Optimizer:  <keras.optimizers.SGD object at 0x2b4edb69c278>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.6093 - acc: 0.6692 - val_loss: 0.5952 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67452, saving model to Model1-6.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 36s 31ms/step - loss: 0.5895 - acc: 0.6740 - val_loss: 0.5945 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.67452\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 36s 30ms/step - loss: 0.5877 - acc: 0.6836 - val_loss: 0.5958 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.67452\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.5871 - acc: 0.6827 - val_loss: 0.5978 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.67452\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 35s 30ms/step - loss: 0.5882 - acc: 0.6774 - val_loss: 0.5955 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.67452\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 37s 32ms/step - loss: 0.5853 - acc: 0.6836 - val_loss: 0.5945 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.67452\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.5839 - acc: 0.6869 - val_loss: 0.5943 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.67452\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 36s 30ms/step - loss: 0.5851 - acc: 0.6827 - val_loss: 0.5945 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.67452\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.5843 - acc: 0.6858 - val_loss: 0.5944 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.67452\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.5841 - acc: 0.6864 - val_loss: 0.5937 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.67452\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 36s 31ms/step - loss: 0.5815 - acc: 0.6906 - val_loss: 0.5927 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.67452 to 0.67677, saving model to Model1-6.h5\n",
      "Training time for this model is 405.18051767349243\n",
      "\n",
      "\n",
      "Loss function:  binary_crossentropy\n",
      "Optimizer:  <keras.optimizers.Adagrad object at 0x2b4edb69c240>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 40s 33ms/step - loss: 0.7862 - acc: 0.6712 - val_loss: 0.6185 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66667, saving model to Model1-7.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.5912 - acc: 0.6833 - val_loss: 0.6154 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.66667\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 37s 32ms/step - loss: 0.5856 - acc: 0.6841 - val_loss: 0.6120 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.66667\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.5819 - acc: 0.6867 - val_loss: 0.6126 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.66667\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.5815 - acc: 0.6883 - val_loss: 0.6105 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.66667\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.5811 - acc: 0.6914 - val_loss: 0.6101 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.66667\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.5704 - acc: 0.6976 - val_loss: 0.6089 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.66667\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.5669 - acc: 0.7002 - val_loss: 0.6081 - val_acc: 0.6655\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.66667\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.5649 - acc: 0.7047 - val_loss: 0.6079 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.66667\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.5626 - acc: 0.7035 - val_loss: 0.6092 - val_acc: 0.6655\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.66667\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.5597 - acc: 0.7120 - val_loss: 0.6092 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.66667\n",
      "Training time for this model is 446.62636947631836\n",
      "\n",
      "\n",
      "Loss function:  binary_crossentropy\n",
      "Optimizer:  <keras.optimizers.Adam object at 0x2b4edb69c320>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 48s 41ms/step - loss: 0.6763 - acc: 0.6582 - val_loss: 0.6026 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66667, saving model to Model1-8.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.5904 - acc: 0.6720 - val_loss: 0.5982 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.66667\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 42s 36ms/step - loss: 0.5855 - acc: 0.6852 - val_loss: 0.5965 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.66667\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.5810 - acc: 0.6872 - val_loss: 0.5951 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.66667\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.5829 - acc: 0.6796 - val_loss: 0.5935 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.66667\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 41s 35ms/step - loss: 0.5769 - acc: 0.6861 - val_loss: 0.5931 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.66667\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.5776 - acc: 0.6855 - val_loss: 0.5922 - val_acc: 0.6622\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.66667\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.5725 - acc: 0.6931 - val_loss: 0.5937 - val_acc: 0.6655\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.66667\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.5740 - acc: 0.6931 - val_loss: 0.5926 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.66667 to 0.67003, saving model to Model1-8.h5\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.5685 - acc: 0.6926 - val_loss: 0.5925 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.67003\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.5693 - acc: 0.6895 - val_loss: 0.5937 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.67003 to 0.67452, saving model to Model1-8.h5\n",
      "Training time for this model is 487.9596948623657\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(combinations)):\n",
    "    loss_function = combinations[i][0]\n",
    "    optimizer = combinations[i][1]\n",
    "    print ('Loss function: ', loss_function)\n",
    "    print ('Optimizer: ', optimizer)\n",
    "    start_time = time.time()\n",
    "    model = build_model(loss_function, optimizer)\n",
    "    modelcheckpoint = ModelCheckpoint('Model1-{}.h5'.format(str(i)), \n",
    "                                            monitor='val_acc', \n",
    "                                            verbose=1, save_best_only=True,  \n",
    "                                            mode='auto', period=1)\n",
    "    model.fit(X_train, Y_train, \n",
    "              batch_size=batch_size, \n",
    "             epochs=epochs, \n",
    "             callbacks=[modelcheckpoint, early_stopping], \n",
    "             validation_data=[X_valid, Y_valid])\n",
    "    print ('Training time for this model is {}'.format(time.time()-start_time))\n",
    "    print ('')\n",
    "    print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 4s 13ms/step\n",
      "297/297 [==============================] - 4s 14ms/step\n",
      "297/297 [==============================] - 4s 13ms/step\n",
      "297/297 [==============================] - 4s 14ms/step\n",
      "297/297 [==============================] - 4s 13ms/step\n",
      "297/297 [==============================] - 4s 14ms/step\n",
      "297/297 [==============================] - 5s 15ms/step\n",
      "297/297 [==============================] - 5s 15ms/step\n",
      "297/297 [==============================] - 4s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model1_paths = glob('Model1-[0-9].h5')\n",
    "scores = []\n",
    "accs = []\n",
    "for path in model1_paths:\n",
    "    model = load_model(path)\n",
    "    score, acc = model.evaluate(X_valid, Y_valid)\n",
    "    scores.append(score)\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best loss-function/optimizer combination is  ('mean_squared_error', <keras.optimizers.Adagrad object at 0x2b4edb69c240>)\n"
     ]
    }
   ],
   "source": [
    "best_acc = max(accs)\n",
    "best_acc_idx = accs.index(best_acc)\n",
    "best_combo = combinations[best_acc_idx]\n",
    "print ('The best loss-function/optimizer combination is ', combinations[best_acc_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results listed above, the combination between mean_squared_error as a loss function and adagrad optimizer is the best combo out of the 9 tested combos. Now let's see if changing the number of batch-size from 16 to 200 would give us a better result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_function = best_combo[0]\n",
    "optimizer = best_combo[1]\n",
    "print ('Loss function: ', loss_function)\n",
    "print ('Optimizer: ', optimizer)\n",
    "start_time = time.time()\n",
    "model1_opt1 = build_model(loss_function, optimizer)\n",
    "modelcheckpoint = ModelCheckpoint('Model1-op1.h5'.format(str(i)), \n",
    "                                        monitor='val_acc', \n",
    "                                        verbose=1, save_best_only=True,  \n",
    "                                        mode='auto', period=1)\n",
    "model1_opt1.fit(X_train, Y_train, \n",
    "          batch_size=200, \n",
    "         epochs=epochs, \n",
    "         callbacks=[modelcheckpoint, early_stopping], \n",
    "         validation_data=[X_valid, Y_valid])\n",
    "print ('Training time for this model is {}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
