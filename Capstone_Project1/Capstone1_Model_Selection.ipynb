{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob \n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = 224\n",
    "img_w = 224\n",
    "def read_img(path,):\n",
    "    'read, resize, and convert an image to grayscale'\n",
    "    img = cv2.imread(path)\n",
    "    resize = cv2.resize(img, (img_h, img_w), cv2.INTER_LINEAR)\n",
    "    #gray = cv2.cvtColor(resize, cv2.COLOR_BGR2GRAY)\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_paths = glob('/storage/Documents/springboard_capstone/capstone1/train/*')\n",
    "test_paths = glob('/storage/Documents/springboard_capstone/capstone1/test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = []\n",
    "for path in type_paths:\n",
    "    train_paths += glob(path+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(paths):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    train_id = []\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        train_id.append(path)\n",
    "        train_data.append(read_img(path))\n",
    "        target = path.split('/')[-2]\n",
    "        train_target.append(target)\n",
    "    print ('Training data load time: {}'.format(time.time() - start_time))\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "def load_test(paths):\n",
    "    test_data = []\n",
    "    test_id = []\n",
    "    start_time = time.time()\n",
    "    for path in paths:\n",
    "        test_id.append(path)\n",
    "        test_data.append(read_img(path))\n",
    "    print ('Testing data load time: {}'.format(time.time() - start_time))\n",
    "    return test_data, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data load time: 342.038950920105\n",
      "Testing data load time: 123.54733157157898\n"
     ]
    }
   ],
   "source": [
    "train_data, train_target, train_id_ = load_train(train_paths)\n",
    "test_data, test_id_ = load_test(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (1481, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "def normalize_data(data):\n",
    "    data = np.array(data, dtype=np.uint8)\n",
    "    data = data.astype('float32')\n",
    "    data = data/255\n",
    "    return data\n",
    "\n",
    "train_data = normalize_data(train_data)\n",
    "print ('Shape of the training data is ', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (503, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_data = normalize_data(test_data)\n",
    "print ('Shape of the training data is ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_target to one-hot-encoding before fitting into the model\n",
    "train_label = [int(x.split('_')[1]) for x in train_target]\n",
    "train_label = np_utils.to_categorical(train_label)\n",
    "train_label = np.transpose(train_label)\n",
    "train_label = np.transpose(train_label[~(train_label==0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation split \n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_label, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training hyperparameters\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping callback\n",
    "patience = 4\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0.05, \n",
    "                              patience = patience, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build the first model with a simple stack of 3 convolution layers with a ReLU activation and max_pooling\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), input_shape=(img_h, img_w, 3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, (3,3), data_format='channels_last'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "#Add flatten\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               22151424  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 22,245,443\n",
      "Trainable params: 22,245,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 376s 318ms/step - loss: 1.0104 - acc: 0.5312 - val_loss: 1.0173 - val_acc: 0.5118\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 357s 302ms/step - loss: 1.0059 - acc: 0.5270 - val_loss: 1.0164 - val_acc: 0.5118\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 325s 274ms/step - loss: 0.9942 - acc: 0.5312 - val_loss: 1.0145 - val_acc: 0.5118\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 299s 252ms/step - loss: 0.9832 - acc: 0.5321 - val_loss: 1.0087 - val_acc: 0.5118\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 282s 238ms/step - loss: 0.9607 - acc: 0.5312 - val_loss: 0.9629 - val_acc: 0.5118\n",
      "The time for fitting training data into model 1 is 1639.1563205718994\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model1.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping],\n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The time for fitting training data into model 1 is {}'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Deep Convolutional NetWorks for Large-Scale Image Recognition (VGG16 Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model \n",
    "\n",
    "vgg16_model = VGG16(weights = 'imagenet', include_top=False, \n",
    "                   input_shape=(img_w, img_h, 3))\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape = vgg16_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model2 = Model(input=vgg16_model.input, output=top_model(vgg16_model.output))\n",
    "model2.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 3)                 6423555   \n",
      "=================================================================\n",
      "Total params: 21,138,243\n",
      "Trainable params: 21,138,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 4532s 4s/step - loss: 12.7385 - acc: 0.1934 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 4646s 4s/step - loss: 13.3410 - acc: 0.1723 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 4649s 4s/step - loss: 13.4499 - acc: 0.1655 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 5276s 4s/step - loss: 13.4635 - acc: 0.1647 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 5414s 5s/step - loss: 13.3818 - acc: 0.1698 - val_loss: 13.1875 - val_acc: 0.1818\n",
      "The time for fitting training data into model 2 is 24517.816619873047\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model2.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping], \n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The time for fitting training data into model 2 is {}'.format(end_time-start_time))\n",
    "model2.save_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ives/anaconda3/lib/python3.6/site-packages/keras_applications/resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/ives/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model \n",
    "\n",
    "resnet50_model = ResNet50(weights = 'imagenet', include_top=False, \n",
    "                   input_shape=(img_w, img_h, 3))\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape =resnet50_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dropout(0.5))\n",
    "add_model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model3 = Model(input=resnet50_model.input, output=add_model(resnet50_model.output))\n",
    "model3.compile(loss='categorical_crossentropy', \n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 3016s 3s/step - loss: 7.5120 - acc: 0.5270 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 2855s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 2537s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 2509s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 2553s 2s/step - loss: 7.5554 - acc: 0.5312 - val_loss: 7.8691 - val_acc: 0.5118\n",
      "The time for fitting training data into model 3 is 13474.341937065125\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model3.fit(X_train, Y_train, \n",
    "         batch_size=batch_size, epochs=epochs, \n",
    "         callbacks=[early_stopping], \n",
    "         validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "print ('The time for fitting training data into model 3 is {}'.format(end_time-start_time))\n",
    "\n",
    "model3.save_weights('model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TUNING ON MODEL 1 USING DIFFERENT COMBINATION OF LOSS FUNCTION AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_selected = np.random.choice(train_paths, size=400)\n",
    "test_paths_selected = np.random.choice(test_paths, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data load time: 79.5964286327362\n",
      "Testing data load time: 19.098011016845703\n"
     ]
    }
   ],
   "source": [
    "train_data_selected, train_target_selected, train_id_selected = load_train(train_paths_selected)\n",
    "test_data_selected, test_id_selected = load_test(test_paths_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_target to one-hot-encoding before fitting into the model\n",
    "train_label_selected = [int(x.split('_')[1]) for x in train_target_selected]\n",
    "train_label_selected = np_utils.to_categorical(train_label_selected)\n",
    "train_label_selected = np.transpose(train_label_selected)\n",
    "train_label_selected = np.transpose(train_label_selected[~(train_label_selected==0).all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (400, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data_selected = normalize_data(train_data_selected)\n",
    "print ('Shape of the training data is ', train_data_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data is  (100, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_data_selected = normalize_data(test_data_selected)\n",
    "print ('Shape of the training data is ', test_data_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation split \n",
    "X_train_selected, X_valid_selected, Y_train_selected, Y_valid_selected = train_test_split(train_data_selected, \n",
    "                                                                                          train_label_selected, \n",
    "                                                                                          test_size=0.2, \n",
    "                                                                                          random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(loss_function, optimizer):\n",
    "    model = Sequential()\n",
    "    kernel_size=(3,3)\n",
    "    data_size=(224,224,3)\n",
    "    for i in range(5, 8):\n",
    "        model.add(Conv2D(2^i, kernel_size, input_shape=data_size, data_format='channels_last'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss=loss_function, optimizer = optimizer, \n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "loss_functions = ['mean_squared_error', \n",
    "                 'categorical_crossentropy', \n",
    "                 'binary_crossentropy']\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adadelta = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "optimizers = [sgd, adadelta, adam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of combinations is  9\n"
     ]
    }
   ],
   "source": [
    "combinations = [loss_functions, optimizers]\n",
    "import itertools\n",
    "combinations = list(itertools.product(*combinations))\n",
    "print ('The number of combinations is ', len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mew Early stopping callback\n",
    "patience = 10\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0.01, \n",
    "                              patience = patience, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function:  mean_squared_error\n",
      "Optimizer:  <keras.optimizers.SGD object at 0x2b4edb69c278>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 34s 29ms/step - loss: 0.2042 - acc: 0.5152 - val_loss: 0.2118 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-0.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 34s 29ms/step - loss: 0.2010 - acc: 0.5304 - val_loss: 0.2088 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.1992 - acc: 0.5321 - val_loss: 0.2068 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.1968 - acc: 0.5312 - val_loss: 0.2040 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51178\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 49s 41ms/step - loss: 0.1941 - acc: 0.5355 - val_loss: 0.2013 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.51178 to 0.52525, saving model to Model1-0.h5\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1949 - acc: 0.5279 - val_loss: 0.2008 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.52525\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1902 - acc: 0.5355 - val_loss: 0.2038 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.52525\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1896 - acc: 0.5456 - val_loss: 0.2012 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.52525\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1875 - acc: 0.5600 - val_loss: 0.1990 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.52525 to 0.52525, saving model to Model1-0.h5\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 48s 41ms/step - loss: 0.1846 - acc: 0.5693 - val_loss: 0.1968 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.52525\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1826 - acc: 0.5693 - val_loss: 0.1995 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.52525\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1792 - acc: 0.5701 - val_loss: 0.1952 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.52525 to 0.53199, saving model to Model1-0.h5\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.1774 - acc: 0.5912 - val_loss: 0.1956 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53199\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 47s 39ms/step - loss: 0.1760 - acc: 0.5938 - val_loss: 0.1958 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.53199 to 0.53535, saving model to Model1-0.h5\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1722 - acc: 0.5954 - val_loss: 0.1947 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.53535\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 43s 37ms/step - loss: 0.1721 - acc: 0.6081 - val_loss: 0.1953 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.53535\n",
      "Epoch 17/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1708 - acc: 0.6284 - val_loss: 0.1937 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.53535\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 49s 42ms/step - loss: 0.1635 - acc: 0.6267 - val_loss: 0.1943 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.53535\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.1659 - acc: 0.6275 - val_loss: 0.1957 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.53535\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 47s 40ms/step - loss: 0.1617 - acc: 0.6326 - val_loss: 0.1968 - val_acc: 0.4983\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.53535\n",
      "Epoch 21/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.1591 - acc: 0.6588 - val_loss: 0.1970 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.53535\n",
      "Epoch 22/50\n",
      "1184/1184 [==============================] - 49s 41ms/step - loss: 0.1611 - acc: 0.6427 - val_loss: 0.1983 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.53535\n",
      "Epoch 23/50\n",
      "1184/1184 [==============================] - 46s 39ms/step - loss: 0.1567 - acc: 0.6520 - val_loss: 0.1995 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.53535\n",
      "Epoch 24/50\n",
      "1184/1184 [==============================] - 43s 37ms/step - loss: 0.1509 - acc: 0.6833 - val_loss: 0.1978 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.53535\n",
      "Training time for this model is 1070.9721937179565\n",
      "\n",
      "\n",
      "Loss function:  mean_squared_error\n",
      "Optimizer:  <keras.optimizers.Adagrad object at 0x2b4edb69c240>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.2851 - acc: 0.5245 - val_loss: 0.2174 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-1.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 43s 36ms/step - loss: 0.2066 - acc: 0.5203 - val_loss: 0.2108 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.2013 - acc: 0.5296 - val_loss: 0.2081 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1966 - acc: 0.5312 - val_loss: 0.2080 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51178\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 42s 35ms/step - loss: 0.1954 - acc: 0.5329 - val_loss: 0.2044 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.51178\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.1923 - acc: 0.5532 - val_loss: 0.2027 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.51178 to 0.53199, saving model to Model1-1.h5\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 50s 42ms/step - loss: 0.1882 - acc: 0.5515 - val_loss: 0.1979 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53199\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.1883 - acc: 0.5600 - val_loss: 0.2031 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53199\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 47s 39ms/step - loss: 0.1819 - acc: 0.5853 - val_loss: 0.1982 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.53199 to 0.53535, saving model to Model1-1.h5\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 45s 38ms/step - loss: 0.1841 - acc: 0.5650 - val_loss: 0.1983 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53535\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 49s 41ms/step - loss: 0.1801 - acc: 0.5777 - val_loss: 0.2011 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53535\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 44s 37ms/step - loss: 0.1745 - acc: 0.5997 - val_loss: 0.1994 - val_acc: 0.5421\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.53535 to 0.54209, saving model to Model1-1.h5\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 40s 33ms/step - loss: 0.1722 - acc: 0.5963 - val_loss: 0.1989 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.54209\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1646 - acc: 0.6292 - val_loss: 0.1987 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.54209\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1649 - acc: 0.6284 - val_loss: 0.1984 - val_acc: 0.5354\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.54209\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1629 - acc: 0.6334 - val_loss: 0.2022 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.54209\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1623 - acc: 0.6267 - val_loss: 0.2017 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.54209\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1542 - acc: 0.6529 - val_loss: 0.2054 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.54209\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1494 - acc: 0.6639 - val_loss: 0.2054 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.54209\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.1449 - acc: 0.6900 - val_loss: 0.2092 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.54209\n",
      "Epoch 21/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.1424 - acc: 0.6765 - val_loss: 0.2065 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.54209\n",
      "Epoch 22/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1381 - acc: 0.7035 - val_loss: 0.2079 - val_acc: 0.4949\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.54209\n",
      "Training time for this model is 941.0249173641205\n",
      "\n",
      "\n",
      "Loss function:  mean_squared_error\n",
      "Optimizer:  <keras.optimizers.Adam object at 0x2b4edb69c320>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 40s 34ms/step - loss: 0.2058 - acc: 0.5177 - val_loss: 0.2176 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52525, saving model to Model1-2.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.2005 - acc: 0.5329 - val_loss: 0.2165 - val_acc: 0.4848\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.52525\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 36s 31ms/step - loss: 0.1998 - acc: 0.5389 - val_loss: 0.2121 - val_acc: 0.5017\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.52525\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1978 - acc: 0.5279 - val_loss: 0.2123 - val_acc: 0.5286\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.52525 to 0.52862, saving model to Model1-2.h5\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1953 - acc: 0.5346 - val_loss: 0.2102 - val_acc: 0.4983\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.52862\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 0.1946 - acc: 0.5481 - val_loss: 0.2086 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.52862 to 0.53199, saving model to Model1-2.h5\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1908 - acc: 0.5574 - val_loss: 0.2070 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53199\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 37s 31ms/step - loss: 0.1889 - acc: 0.5549 - val_loss: 0.2056 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53199\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1772 - acc: 0.5870 - val_loss: 0.2012 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53199\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 37s 32ms/step - loss: 0.1710 - acc: 0.6090 - val_loss: 0.2015 - val_acc: 0.5219\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53199\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 0.1687 - acc: 0.6174 - val_loss: 0.2031 - val_acc: 0.5084\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53199\n",
      "Training time for this model is 419.04780745506287\n",
      "\n",
      "\n",
      "Loss function:  categorical_crossentropy\n",
      "Optimizer:  <keras.optimizers.SGD object at 0x2b4edb69c278>\n",
      "Train on 1184 samples, validate on 297 samples\n",
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 39s 33ms/step - loss: 1.0390 - acc: 0.5177 - val_loss: 1.0265 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51178, saving model to Model1-3.h5\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 38s 32ms/step - loss: 1.0033 - acc: 0.5312 - val_loss: 1.0207 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51178\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 48s 40ms/step - loss: 0.9980 - acc: 0.5312 - val_loss: 1.0176 - val_acc: 0.5118\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51178\n",
      "Epoch 4/50\n",
      " 400/1184 [=========>....................] - ETA: 27s - loss: 0.9874 - acc: 0.5325"
     ]
    }
   ],
   "source": [
    "for i in range(len(combinations)):\n",
    "    loss_function = combinations[i][0]\n",
    "    optimizer = combinations[i][1]\n",
    "    print ('Loss function: ', loss_function)\n",
    "    print ('Optimizer: ', optimizer)\n",
    "    start_time = time.time()\n",
    "    model = build_model(loss_function, optimizer)\n",
    "    modelcheckpoint = ModelCheckpoint('Model1-{}.h5'.format(str(i)), \n",
    "                                            monitor='val_acc', \n",
    "                                            verbose=1, save_best_only=True,  \n",
    "                                            mode='auto', period=1)\n",
    "    model.fit(X_train, Y_train, \n",
    "              batch_size=batch_size, \n",
    "             epochs=epochs, \n",
    "             callbacks=[modelcheckpoint, early_stopping], \n",
    "             validation_data=[X_valid, Y_valid])\n",
    "    print ('Training time for this model is {}'.format(time.time()-start_time))\n",
    "    print ('')\n",
    "    print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8b0f1d22466f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model1.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.weights'"
     ]
    }
   ],
   "source": [
    "from keras.weights import load_weights\n",
    "model = load_weights('best_model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
